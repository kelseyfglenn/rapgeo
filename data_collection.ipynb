{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597104935903",
   "display_name": "Python 3.7.7 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import quote\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pickle as pkl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load artist names.\n",
    "\"\"\"\n",
    "with open('artist_names.pkl', 'rb') as f: \n",
    "    artists = pkl.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load artist API paths. \n",
    "\"\"\"\n",
    "with open('all_artist_paths.pkl', 'rb') as f:\n",
    "    all_artist_paths = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load song paths for every artist. \n",
    "\"\"\"\n",
    "with open('all_song_paths.pkl', 'rb') as f: \n",
    "    all_song_paths = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load all song lyrics.\n",
    "\"\"\"\n",
    "with open('all_song_lyrics.pkl', 'rb') as f: \n",
    "    all_song_lyrics = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Request and Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base genius endpoint\n",
    "url_api = \"https://api.genius.com\"\n",
    "\n",
    "# access token and request headers for API query\n",
    "with open('client_access_token.txt', 'r') as f:\n",
    "    client_access_token = f.read()\n",
    "\n",
    "# headers for API requests\n",
    "headers = {\"Authorization\": \"Bearer \" + client_access_token, \"User-Agent\":\"\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_path(artist_name):\n",
    "    # generate and store url, modify artist name to remove spaces\n",
    "    url_search = \"/search?q=\" \n",
    "    querystring = url_api + url_search + quote(artist_name)\n",
    "    # get API response\n",
    "    response = requests.get(querystring, headers=headers)\n",
    "    response_artist = response.json()\n",
    "    # pull artist url -- assumes they are the primary artist in the first search result since all searches return song objects\n",
    "    url_artist = response_artist['response']['hits'][0]['result']['primary_artist']['api_path']\n",
    "\n",
    "    return url_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_list(url_artist):\n",
    "    # get the first per_page songs returned for that artist\n",
    "    per_page = 50\n",
    "    querystring = url_api + url_artist + \"/songs\" + \"?per_page=\" + str(per_page)\n",
    "    response_songs = requests.get(querystring, headers = headers)\n",
    "    songs = response_songs.json()\n",
    "\n",
    "    # reduce songs to only those where target artist is the primary artist\n",
    "    drops = []\n",
    "    for index, song in enumerate(songs['response']['songs']):\n",
    "        if song['primary_artist']['api_path'] != url_artist:\n",
    "            drops.append(index)\n",
    "    for index in sorted(drops, reverse=True):\n",
    "        del songs['response']['songs'][index]\n",
    "\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_paths(songs):\n",
    "    song_paths = []\n",
    "    for song in songs['response']['songs']: \n",
    "        song_paths.append(song['api_path'])\n",
    "    return song_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics(song_path):\n",
    "    url = 'https://genius.com' + song_path\n",
    "    lyrics_page = requests.get(url).text\n",
    "    lyrics_soup = BeautifulSoup(lyrics_page)\n",
    "    lyrics = lyrics_soup.find_all('div', class_='lyrics')[0].find('p').text\n",
    "    return lyrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping and API Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\nScraping/cleaning/storing artist names from Wikipedia.\\n'"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "\"\"\"\n",
    "Scraping/cleaning/storing artist names from Wikipedia.\n",
    "\"\"\"\n",
    "\n",
    "# # Scrape ~1400 popular hip hop musicians from wikipedia\n",
    "# response = requests.get('https://en.wikipedia.org/wiki/List_of_hip_hop_musicians').text\n",
    "# soup = BeautifulSoup(response)\n",
    "\n",
    "# artist_tags = []\n",
    "# for item in soup.find_all('li'): \n",
    "#     artist_tags.append(item.text)\n",
    "\n",
    "# artists = artist_tags[29:-61]\n",
    "\n",
    "# # remove annotation links (e.g. 'Drake[1]' -> 'Drake')\n",
    "# # remove parenthesized annotations\n",
    "# annotations_list = set([artist for artist in artists if artist[-1] == ']'])\n",
    "# drops = []\n",
    "# for index, artist in enumerate(artists):\n",
    "#     if artist in annotations_list: \n",
    "#         artists[index] = artist[:-3]\n",
    "#     if artist == 'Torch (American)': \n",
    "#         artists[index] = 'Torch (Triple C)'\n",
    "#     if artist == 'Torch (German)':\n",
    "#         artists[index] = 'Torch'\n",
    "#     if artist == 'Casanova (rapper)':\n",
    "#         artists[index] = 'Casanova'\n",
    "#     if artist == 'Alias (musician)' or artist == 'Juice (ƒêus)':\n",
    "#         drops.append(index)\n",
    "\n",
    "# for index in sorted(drops, reverse=True): \n",
    "#     del artists[index]\n",
    "\n",
    "# # Store as pickle\n",
    "# with open('artist_names.pkl', 'rb') as f: \n",
    "#     pkl.dump(artists, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\nPull and store artist API paths. \\n'"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pull and store artist API paths. \n",
    "\"\"\"\n",
    "# # Pull artist API path for each artist in list\n",
    "# all_artist_paths = {}\n",
    "# for artist in artists:\n",
    "#     try:\n",
    "#         all_artist_paths[artist] = get_artist_path(artist)\n",
    "#     except:\n",
    "#         all_artist_paths[artist] = None    \n",
    "#\n",
    "# with open('all_artist_paths.pkl', 'wb') as f:\n",
    "#     pkl.dump(all_artist_paths, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\nPull and store song paths by artist. \\n'"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pull and store song paths by artist. \n",
    "\"\"\"\n",
    "# all_song_paths = {}\n",
    "# for artist in artists:\n",
    "#     path = all_artist_paths[artist]\n",
    "#     try: \n",
    "#         songs = get_song_list(path)\n",
    "#         all_song_paths[artist] = get_song_paths(songs)\n",
    "#     except:\n",
    "#         all_song_paths[artist] = None\n",
    "\n",
    "# with open('all_song_paths.pkl', 'wb') as f:\n",
    "#     pkl.dump(all_song_paths, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\nScrape and store lyrics for each song\\n'"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "\"\"\"\n",
    "Scrape and store lyrics for each song\n",
    "\"\"\"\n",
    "# all_song_lyrics = {}\n",
    "# for artist in artists:\n",
    "#     all_song_lyrics[artist] = {}\n",
    "#     try:       \n",
    "#         for song in all_song_paths[artist]:\n",
    "#             lyrics = get_lyrics(song)\n",
    "#             all_song_lyrics[artist][song] = lyrics\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "# with open('all_song_lyrics.pkl', 'wb') as f:\n",
    "#     pkl.dump(all_song_lyrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify artists who we failed to pull lyrics for\n",
    "skipped_artists = [artist for artist in all_song_lyrics.keys() if all_song_lyrics[artist] == {}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e9485d4be8f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0martist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskipped_artists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mskipped_song_lyrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msong\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_song_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mlyrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lyrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Try again in case it was due to some request error\n",
    "skipped_song_lyrics = {}\n",
    "for artist in skipped_artists[3:]:\n",
    "    skipped_song_lyrics[artist] = {}  \n",
    "    for song in all_song_paths[artist]:\n",
    "        try:\n",
    "            lyrics = get_lyrics(song)\n",
    "            skipped_song_lyrics[artist][song] = lyrics\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_song_lyrics_v2 = all_song_lyrics.copy()\n",
    "for artist in skipped_song_lyrics.keys(): \n",
    "    all_song_lyrics_v2[artist] = skipped_song_lyrics[artist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_song_lyrics_v2.pkl', 'wb') as f: \n",
    "    pkl.dump(all_song_lyrics_v2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['A Boogie wit da Hoodie',\n 'A$AP Rocky',\n 'BlocBoy JB',\n 'DJ Khalil',\n 'Drumma Boy',\n 'Easy Mo Bee',\n 'Jim Jonsin',\n 'Jorma Taccone',\n 'Lex Luger',\n 'London On Da Track',\n 'Luis Resto',\n 'Meechy Darko',\n 'Warryn Campbell',\n 'Your Old Droog',\n 'Yung Berg',\n 'Zaytoven',\n 'ZillaKami',\n 'Zombie Juice']"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "[artist for artist in all_song_lyrics_v2.keys() if all_song_lyrics_v2[artist] == {}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kanye = all_song_paths['Kanye West']\n",
    "kanye_lyrics = {}\n",
    "for song in kanye: \n",
    "    try:\n",
    "        lyrics = get_lyrics(song)\n",
    "        kanye_lyrics[song] = lyrics\n",
    "    except: \n",
    "        kanye_lyrics[song] = 'nope'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['A Boogie wit da Hoodie',\n 'A$AP Rocky',\n 'BlocBoy JB',\n 'Yung Berg',\n 'Zaytoven',\n 'ZillaKami',\n 'Zombie Juice']"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "[artist for artist in skipped_artists if artist not in skipped_song_lyrics.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}