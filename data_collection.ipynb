{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597028496791",
   "display_name": "Python 3.7.7 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import quote\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pickle as pkl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load artist names.\n",
    "\"\"\"\n",
    "with open('artist_names.pkl', 'rb') as f: \n",
    "    artists = pkl.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load artist API paths. \n",
    "\"\"\"\n",
    "with open('all_artist_paths.pkl', 'rb') as f:\n",
    "    all_artist_paths = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load song paths for every artist. \n",
    "\"\"\"\n",
    "with open('all_song_paths.pkl', 'rb') as f: \n",
    "    all_song_paths = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Request and Scraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base genius endpoint\n",
    "url_api = \"https://api.genius.com\"\n",
    "\n",
    "# headers for API requests\n",
    "headers = {\"Authorization\": \"Bearer \" + client_access_token, \"User-Agent\":\"\"}\n",
    "\n",
    "# access token and request headers for API query\n",
    "with open('client_access_token.txt', 'r') as f:\n",
    "    client_access_token = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_path(artist_name):\n",
    "    # generate and store url, modify artist name to remove spaces\n",
    "    url_search = \"/search?q=\" \n",
    "    querystring = url_api + url_search + quote(artist_name)\n",
    "    # get API response\n",
    "    response = requests.get(querystring, headers=headers)\n",
    "    response_artist = response.json()\n",
    "    # pull artist url -- assumes they are the primary artist in the first search result since all searches return song objects\n",
    "    url_artist = response_artist['response']['hits'][0]['result']['primary_artist']['api_path']\n",
    "\n",
    "    return url_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_list(url_artist):\n",
    "    # get the first per_page songs returned for that artist\n",
    "    per_page = 50\n",
    "    querystring = url_api + url_artist + \"/songs\" + \"?per_page=\" + str(per_page)\n",
    "    response_songs = requests.get(querystring, headers = headers)\n",
    "    songs = response_songs.json()\n",
    "\n",
    "    # reduce songs to only those where target artist is the primary artist\n",
    "    drops = []\n",
    "    for index, song in enumerate(songs['response']['songs']):\n",
    "        if song['primary_artist']['api_path'] != url_artist:\n",
    "            drops.append(index)\n",
    "    for index in sorted(drops, reverse=True):\n",
    "        del songs['response']['songs'][index]\n",
    "\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song_paths(songs):\n",
    "    song_paths = []\n",
    "    for song in songs['response']['songs']: \n",
    "        song_paths.append(song['api_path'])\n",
    "    return song_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_artist_songs(artist):\n",
    "#     path = all_artist_paths[artist]\n",
    "#     songs = get_song_list(path)\n",
    "#     paths = get_song_paths(songs)\n",
    "\n",
    "#     return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_all_artist_songs(artist_names):\n",
    "#     artist_songs = {}\n",
    "#     for artist in artist_names:\n",
    "#         try:\n",
    "#             artist_songs[artist] = get_artist_songs(artist)\n",
    "#         except:\n",
    "#             artist_songs[artist] = None\n",
    "#     return artist_songs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics(song_path):\n",
    "    url = 'https://genius.com' + song_path\n",
    "    lyrics_page = requests.get(url).text\n",
    "    lyrics_soup = BeautifulSoup(lyrics_page)\n",
    "    lyrics = lyrics_soup.find_all('div', class_='lyrics')[0].find('p').text\n",
    "    return lyrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping and API Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scraping/cleaning/storing artist names from Wikipedia.\n",
    "\"\"\"\n",
    "\n",
    "# # Scrape ~1400 popular hip hop musicians from wikipedia\n",
    "# response = requests.get('https://en.wikipedia.org/wiki/List_of_hip_hop_musicians').text\n",
    "# soup = BeautifulSoup(response)\n",
    "\n",
    "# artist_tags = []\n",
    "# for item in soup.find_all('li'): \n",
    "#     artist_tags.append(item.text)\n",
    "\n",
    "# artists = artist_tags[29:-61]\n",
    "\n",
    "# # remove annotation links (e.g. 'Drake[1]' -> 'Drake')\n",
    "# # remove parenthesized annotations\n",
    "# annotations_list = set([artist for artist in artists if artist[-1] == ']'])\n",
    "# drops = []\n",
    "# for index, artist in enumerate(artists):\n",
    "#     if artist in annotations_list: \n",
    "#         artists[index] = artist[:-3]\n",
    "#     if artist == 'Torch (American)': \n",
    "#         artists[index] = 'Torch (Triple C)'\n",
    "#     if artist == 'Torch (German)':\n",
    "#         artists[index] = 'Torch'\n",
    "#     if artist == 'Casanova (rapper)':\n",
    "#         artists[index] = 'Casanova'\n",
    "#     if artist == 'Alias (musician)' or artist == 'Juice (ƒêus)':\n",
    "#         drops.append(index)\n",
    "\n",
    "# for index in sorted(drops, reverse=True): \n",
    "#     del artists[index]\n",
    "\n",
    "# # Store as pickle\n",
    "# with open('artist_names.pkl', 'rb') as f: \n",
    "#     pkl.dump(artists, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pull and store artist API paths. \n",
    "\"\"\"\n",
    "# # Pull artist API path for each artist in list\n",
    "# all_artist_paths = {}\n",
    "# for artist in artists:\n",
    "#     try:\n",
    "#         all_artist_paths[artist] = get_artist_path(artist)\n",
    "#     except:\n",
    "#         all_artist_paths[artist] = None    \n",
    "#\n",
    "# with open('all_artist_paths.pkl', 'wb') as f:\n",
    "#     pkl.dump(all_artist_paths, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pull and store song paths by artist. \n",
    "\"\"\"\n",
    "# all_song_paths = {}\n",
    "# for artist in artists:\n",
    "#     path = all_artist_paths[artist]\n",
    "#     try: \n",
    "#         songs = get_song_list(path)\n",
    "#         all_song_paths[artist] = get_song_paths(songs)\n",
    "#     except:\n",
    "#         all_song_paths[artist] = None\n",
    "\n",
    "# with open('all_song_paths.pkl', 'wb') as f:\n",
    "#     pkl.dump(all_song_paths, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scrape and store lyrics for each song\n",
    "\"\"\"\n",
    "all_song_lyrics = {}\n",
    "for artist in artists:\n",
    "    all_song_lyrics[artist] = {}\n",
    "    try:       \n",
    "        for song in all_song_paths[artist]:\n",
    "            lyrics = get_lyrics(song)\n",
    "            all_song_lyrics[artist][song] = lyrics\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "12"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "with open('all_song_lyrics.pkl', 'wb') as f:\n",
    "    pkl.dump(all_song_lyrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}